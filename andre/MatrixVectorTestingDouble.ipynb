{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "    Jupyter notebook for accessing CUDA\n",
    "    Copyright (C) 2018 Andre.Brodtkorb@ifi.uio.no, changed in October by Andr√© Brodtkorb\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "import pycuda.driver as cuda_driver\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import IPythonMagic\n",
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from ipytest import run_pytest, clean_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python version 3.6.6 | packaged by conda-forge | (default, Jul 26 2018, 09:53:17) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "Registering context in user workspace\n",
      "Creating context\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (8, 0, 0)\n",
      "Driver version 9010\n",
      "Using 'Quadro K2000' GPU\n",
      " => compute capability: (3, 0)\n",
      " => memory: 1895 / 1999 MB available\n",
      "Created context handle <52789040>\n",
      "Using CUDA cache dir /home/jobic/test/cuda/milan2018/MilanoGPU2018/andre/cuda_cache\n"
     ]
    }
   ],
   "source": [
    "%setup_logging\n",
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_kernel = \"\"\"\n",
    "__global__ void matrixVectorKernel(double* c, double* A, double* b, int a_rows, int a_cols) {\n",
    "    unsigned int j = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    \n",
    "    //Out of bounds check\n",
    "    if (j > a_rows) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    //Compute inner product of row of A with column of B\n",
    "    float sum = 0.0f;\n",
    "    for (int i=0; i<a_cols; ++i) {\n",
    "        unsigned int k = j*a_cols + i;\n",
    "        sum += A[k] * b[i];\n",
    "    }\n",
    "    \n",
    "    //Write to global memory\n",
    "    c[j] = sum;\n",
    "}\n",
    "\"\"\"\n",
    "module = cuda_compiler.SourceModule(cuda_kernel)\n",
    "kernel = module.get_function(\"matrixVectorKernel\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpuMatrixVector(a, b):\n",
    "    context.synchronize()\n",
    "        \n",
    "        \n",
    "    #Upload data to the device\n",
    "    #NOTE: We need to make sure that a=(a_rows, a_columns)\n",
    "    # and that b=(a_colmuns, 1) (column vector)\n",
    "    # and that c=(a_rows, 1)\n",
    "    with Timer(\"Data allocation\") as t:\n",
    "        a_g = GPUArray(a.shape, np.float64)\n",
    "        b_g = GPUArray(b.shape, np.float64)\n",
    "        c_g = GPUArray(a.shape[0], np.float64)\n",
    "        context.synchronize()\n",
    "        \n",
    "    with Timer(\"A upload\") as t:\n",
    "        a_g.set(a)\n",
    "        context.synchronize()\n",
    "        \n",
    "    with Timer(\"b upload\") as t:\n",
    "        b_g.set(b)\n",
    "        context.synchronize()\n",
    "    \n",
    "    #NOTE: We need to change this so that the grid*block is x = 1, y = number of rows in A\n",
    "    block_size = (128, 1, 1) #These need to be [x, y, z]\n",
    "    grid_size = (int(np.ceil(a.shape[0] / 128)), 1, 1)\n",
    "\n",
    "    #print(\"Block size is \" + str(block_size))\n",
    "    #print(\"Grid size is \" + str(grid_size))\n",
    "    \n",
    "    #Execute program on device\n",
    "    with Timer(\"Kernel execution\") as t:\n",
    "        kernel(c_g, a_g, b_g, np.int32(a.shape[0]), np.int32(a.shape[1]), block=block_size, grid=grid_size)\n",
    "        context.synchronize()\n",
    "\n",
    "    #Copy data from device to host\n",
    "    with Timer(\"Allocate c\") as t:\n",
    "        c = np.empty((a.shape[0], 1), dtype=np.float64)\n",
    "    with Timer(\"Download\") as t:\n",
    "        c_g.get(c)\n",
    "        context.synchronize()\n",
    "    \n",
    "    #Return our computed matrix-vector product\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  200   400   800  1600  3200  6400  8000 10000] [  200   400   800  1600  3200  6400  8000 10000]\n"
     ]
    }
   ],
   "source": [
    "nx = np.array([200, 400, 800, 1600, 3200, 6400, 8000, 10000])\n",
    "ny = nx\n",
    "\n",
    "print(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 1.846313 ms\n",
      "Data allocation: 1.546144 ms\n",
      "A upload: 1.411438 ms\n",
      "b upload: 0.992537 ms\n",
      "Kernel execution: 3.175974 ms\n",
      "Allocate c: 0.022888 ms\n",
      "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:39: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "Download: 4.278898 ms\n",
      "Run whole function: 20.333052 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 5.489111 ms\n",
      "Data allocation: 1.687527 ms\n",
      "A upload: 1.189232 ms\n",
      "b upload: 0.982046 ms\n",
      "Kernel execution: 0.910521 ms\n",
      "Allocate c: 0.015974 ms\n",
      "Download: 0.213385 ms\n",
      "Run whole function: 13.293743 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 18.190145 ms\n",
      "Data allocation: 0.819206 ms\n",
      "A upload: 3.386021 ms\n",
      "b upload: 0.797749 ms\n",
      "Kernel execution: 1.469374 ms\n",
      "Allocate c: 0.013590 ms\n",
      "Download: 0.332832 ms\n",
      "Run whole function: 13.026953 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 52.868843 ms\n",
      "Data allocation: 0.936747 ms\n",
      "A upload: 12.872458 ms\n",
      "b upload: 0.790119 ms\n",
      "Kernel execution: 3.877878 ms\n",
      "Allocate c: 0.013828 ms\n",
      "Download: 1.091242 ms\n",
      "Run whole function: 25.064945 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 192.032337 ms\n",
      "Data allocation: 1.177788 ms\n",
      "A upload: 52.258015 ms\n",
      "b upload: 0.836611 ms\n",
      "Kernel execution: 18.068314 ms\n",
      "Allocate c: 0.017166 ms\n",
      "Download: 1.221657 ms\n",
      "Run whole function: 79.734325 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 736.355305 ms\n",
      "Data allocation: 1.222849 ms\n",
      "A upload: 198.377609 ms\n",
      "b upload: 0.837326 ms\n",
      "Kernel execution: 82.882404 ms\n",
      "Allocate c: 0.014544 ms\n",
      "Download: 0.369549 ms\n",
      "Run whole function: 288.824797 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 945.788622 ms\n",
      "Data allocation: 2.199173 ms\n",
      "A upload: 310.403585 ms\n",
      "b upload: 0.647783 ms\n",
      "Kernel execution: 129.801989 ms\n",
      "Allocate c: 0.034809 ms\n",
      "Download: 0.415087 ms\n",
      "Run whole function: 449.825048 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 1474.076033 ms\n",
      "Data allocation: 1.755476 ms\n",
      "A upload: 484.122753 ms\n",
      "b upload: 0.358820 ms\n",
      "Kernel execution: 211.913347 ms\n",
      "Allocate c: 0.059366 ms\n",
      "Download: 0.715733 ms\n",
      "Run whole function: 707.185507 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    40000    160000    640000   2560000  10240000  40960000  64000000\n",
      " 100000000]\n",
      "[ 20  13  13  25  79 288 449 707]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fig = plt.figure()\\nplt.subplot(1,3,1)\\nplt.imshow(a)\\nplt.subplot(1,3,2)\\nplt.imshow(b)\\nplt.subplot(1,3,3)\\nplt.imshow(c)\\nfig.show()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = np.empty_like(nx)\n",
    "for i in range(len(nx)):\n",
    "    print(\"Nx = \" + str(nx[i]), flush=True)\n",
    "    #Size of our test\n",
    "    test_size = (nx[i], ny[i])\n",
    "\n",
    "    #Create test input / output data\n",
    "    with Timer(\"Create test data\") as t:\n",
    "        a = np.random.random(test_size).astype(np.float64)\n",
    "        b = np.random.random((test_size[1], 1)).astype(np.float64)\n",
    "    with Timer(\"Run whole function\") as t:\n",
    "        c = gpuMatrixVector(a, b)\n",
    "    times[i] = t.msecs\n",
    "    \n",
    "print(nx*ny)\n",
    "print(times)\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\"fig = plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(a)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(b)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(c)\n",
    "fig.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcee15d9860>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_title_pos\n",
      "findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(nx*ny, times, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad = 30.624646187327925872523337602615\n",
      "Per element error: 0.0030624646187327924\n"
     ]
    }
   ],
   "source": [
    "#Compute reference using Numpy\n",
    "c_ref = np.dot(a, b)\n",
    "\n",
    "#Sum of absolute differences\n",
    "sad = np.sum(np.abs(c - c_ref))\n",
    "\n",
    "#Print result\n",
    "# print(\"C   = \", c)\n",
    "# print(\"Ref = \", c_ref)\n",
    "print(\"Sad = %.30f\" % sad)\n",
    "print(\"Per element error: \" + str(sad / test_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tests()\n",
    "\n",
    "def test_gpuMatrixVector():\n",
    "    #Let us test a matrix of size 1x1\n",
    "    a = np.ones((1, 1), dtype=np.float32)\n",
    "    b = 2*np.ones((1, 1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(2.0)\n",
    "    \n",
    "    #Test that the inner product works\n",
    "    a = np.ones((1, 2), dtype=np.float32)\n",
    "    b = 2*np.ones((2, 1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(4.0)\n",
    "    \n",
    "    #Test a general matrix\n",
    "    test_size = (4, 3)\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(a.dot(b), rel=1e-3)\n",
    "    \n",
    "run_pytest(filename='MatrixVectorTesting.ipynb', pytest_options=['-vvv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpudev]",
   "language": "python",
   "name": "conda-env-gpudev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
