{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "    Jupyter notebook for accessing CUDA\n",
    "    Copyright (C) 2018 Andre.Brodtkorb@ifi.uio.no, changed in October by Andr√© Brodtkorb\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "import pycuda.driver as cuda_driver\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import IPythonMagic\n",
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from ipytest import run_pytest, clean_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global logger already initialized!\n",
      "Registering context in user workspace\n",
      "Context already registered! Ignoring\n"
     ]
    }
   ],
   "source": [
    "%setup_logging\n",
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pycuda._driver.Function at 0x7f736de87768>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_kernel = \"\"\"\n",
    "__global__ void matrixVectorKernel(float* c, float* A, float* b, int a_rows, int a_cols) {\n",
    "    unsigned int j = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    \n",
    "    //Out of bounds check\n",
    "    if (j > a_rows) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    //Compute inner product of row of A with column of B\n",
    "    float sum = 0.0f;\n",
    "    for (int i=0; i<a_cols; ++i) {\n",
    "        unsigned int k = j*a_cols + i;\n",
    "        sum += A[k] * b[i];\n",
    "    }\n",
    "    \n",
    "    //Write to global memory\n",
    "    c[j] = sum;\n",
    "}\n",
    "\"\"\"\n",
    "module = cuda_compiler.SourceModule(cuda_kernel)\n",
    "kernel = module.get_function(\"matrixVectorKernel\");\n",
    "#float* c, float* A, float* b, int a_rows, int a_cols\n",
    "kernel.prepare('PPPii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpuMatrixVector_async(a, b):\n",
    "    #create a stream of operations on GPU\n",
    "    stream = cuda_driver.Stream()\n",
    "    #context.synchronize()\n",
    "        \n",
    "        \n",
    "    #Upload data to the device\n",
    "    #NOTE: We need to make sure that a=(a_rows, a_columns)\n",
    "    # and that b=(a_colmuns, 1) (column vector)\n",
    "    # and that c=(a_rows, 1)\n",
    "    with Timer(\"Data allocation\") as t:\n",
    "        a_g = GPUArray(a.shape, np.float32)\n",
    "        b_g = GPUArray(b.shape, np.float32)\n",
    "        c_g = GPUArray(a.shape[0], np.float32)\n",
    "        #context.synchronize()\n",
    "        \n",
    "    with Timer(\"A upload\") as t:\n",
    "        a_g.set_async(a,stream=stream)\n",
    "        #context.synchronize()\n",
    "        \n",
    "    with Timer(\"b upload\") as t:\n",
    "        b_g.set_async(b,stream=stream)\n",
    "        #context.synchronize()\n",
    "    \n",
    "    #NOTE: We need to change this so that the grid*block is x = 1, y = number of rows in A\n",
    "    block_size = (256, 1, 1) #These need to be [x, y, z]\n",
    "    grid_size = (int(np.ceil(a.shape[0] / block_size[0])), 1, 1)\n",
    "\n",
    "    #print(\"Block size is \" + str(block_size))\n",
    "    #print(\"Grid size is \" + str(grid_size))\n",
    "    \n",
    "    #Execute program on device\n",
    "    with Timer(\"Kernel execution\") as t:\n",
    "        kernel.prepared_async_call(grid_size,block_size,stream,\\\n",
    "                                   c_g.gpudata, a_g.gpudata, b_g.gpudata, \\\n",
    "                                   np.int32(a.shape[0]), np.int32(a.shape[1]))\n",
    "        #context.synchronize()\n",
    "\n",
    "    #Copy data from device to host\n",
    "    with Timer(\"Allocate c\") as t:\n",
    "        c = np.empty((a.shape[0], 1), dtype=np.float32)\n",
    "    with Timer(\"Download\") as t:\n",
    "        c_g.get(c)\n",
    "        #context.synchronize()\n",
    "    \n",
    "    #Return our computed matrix-vector product\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 97.867727 ms\n",
      "Data allocation: 0.799894 ms\n",
      "A upload: 6.119967 ms\n",
      "b upload: 0.375032 ms\n",
      "Kernel execution: 0.101089 ms\n",
      "Allocate c: 0.011444 ms\n",
      "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:43: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "Download: 4.055977 ms\n",
      "Run whole function: 19.119978 ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dc3bba3b4be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run whole function\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpuMatrixVector_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'times' is not defined"
     ]
    }
   ],
   "source": [
    "#Size of our test\n",
    "test_size = (2048,2048)\n",
    "\n",
    "#Create test input / output data\n",
    "with Timer(\"Create test data\") as t:\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "with Timer(\"Run whole function\") as t:\n",
    "    c = gpuMatrixVector_async(a, b)\n",
    "times[i] = t.msecs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a virer les synchro\n",
    "```\n",
    "Create test data: 99.756002 ms\n",
    "Data allocation: 0.729561 ms\n",
    "A upload: 6.402254 ms\n",
    "b upload: 0.203848 ms\n",
    "Kernel execution: 0.093699 ms\n",
    "Allocate c: 0.012159 ms\n",
    "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:43: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
    "Download: 3.669262 ms\n",
    "Run whole function: 19.295216 ms\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpuMatrixVector_nosync(a, b):\n",
    "    #create a stream of operations on GPU\n",
    "    stream = cuda_driver.Stream()\n",
    "    #context.synchronize()\n",
    "        \n",
    "        \n",
    "    #Upload data to the device\n",
    "    #NOTE: We need to make sure that a=(a_rows, a_columns)\n",
    "    # and that b=(a_colmuns, 1) (column vector)\n",
    "    # and that c=(a_rows, 1)\n",
    "    with Timer(\"Data allocation\") as t:\n",
    "        a_g = GPUArray(a.shape, np.float32)\n",
    "        b_g = GPUArray(b.shape, np.float32)\n",
    "        c_g = GPUArray(a.shape[0], np.float32)\n",
    "        #context.synchronize()\n",
    "        \n",
    "    with Timer(\"A upload\") as t:\n",
    "        a_g.set(a)\n",
    "        #context.synchronize()\n",
    "        \n",
    "    with Timer(\"b upload\") as t:\n",
    "        b_g.set(b)\n",
    "        #context.synchronize()\n",
    "    \n",
    "    #NOTE: We need to change this so that the grid*block is x = 1, y = number of rows in A\n",
    "    block_size = (256, 1, 1) #These need to be [x, y, z]\n",
    "    grid_size = (int(np.ceil(a.shape[0] / block_size[0])), 1, 1)\n",
    "\n",
    "    #print(\"Block size is \" + str(block_size))\n",
    "    #print(\"Grid size is \" + str(grid_size))\n",
    "    \n",
    "    #Execute program on device\n",
    "    with Timer(\"Kernel execution\") as t:\n",
    "        kernel.prepared_async_call(grid_size,block_size,stream,\\\n",
    "                                   c_g.gpudata, a_g.gpudata, b_g.gpudata, \\\n",
    "                                   np.int32(a.shape[0]), np.int32(a.shape[1]))\n",
    "        #context.synchronize()\n",
    "\n",
    "    #Copy data from device to host\n",
    "    with Timer(\"Allocate c\") as t:\n",
    "        c = np.empty((a.shape[0], 1), dtype=np.float32)\n",
    "    with Timer(\"Download\") as t:\n",
    "        c_g.get(c)\n",
    "        #context.synchronize()\n",
    "    \n",
    "    #Return our computed matrix-vector product\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 102.025986 ms\n",
      "Data allocation: 0.799179 ms\n",
      "A upload: 6.199360 ms\n",
      "b upload: 0.387907 ms\n",
      "Kernel execution: 0.086784 ms\n",
      "Allocate c: 0.013590 ms\n",
      "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:43: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "Download: 3.982544 ms\n",
      "Run whole function: 19.251585 ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d19a43101ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run whole function\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpuMatrixVector_nosync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'times' is not defined"
     ]
    }
   ],
   "source": [
    "#Size of our test\n",
    "test_size = (2048,2048)\n",
    "\n",
    "#Create test input / output data\n",
    "with Timer(\"Create test data\") as t:\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "with Timer(\"Run whole function\") as t:\n",
    "    c = gpuMatrixVector_nosync(a, b)\n",
    "times[i] = t.msecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpuMatrixVector_sync(a, b):\n",
    "    #create a stream of operations on GPU\n",
    "    stream = cuda_driver.Stream()\n",
    "    context.synchronize()\n",
    "        \n",
    "        \n",
    "    #Upload data to the device\n",
    "    #NOTE: We need to make sure that a=(a_rows, a_columns)\n",
    "    # and that b=(a_colmuns, 1) (column vector)\n",
    "    # and that c=(a_rows, 1)\n",
    "    with Timer(\"Data allocation\") as t:\n",
    "        a_g = GPUArray(a.shape, np.float32)\n",
    "        b_g = GPUArray(b.shape, np.float32)\n",
    "        c_g = GPUArray(a.shape[0], np.float32)\n",
    "        context.synchronize()\n",
    "        \n",
    "    with Timer(\"A upload\") as t:\n",
    "        a_g.set(a)\n",
    "        context.synchronize()\n",
    "        \n",
    "    with Timer(\"b upload\") as t:\n",
    "        b_g.set(b)\n",
    "        context.synchronize()\n",
    "    \n",
    "    #NOTE: We need to change this so that the grid*block is x = 1, y = number of rows in A\n",
    "    block_size = (256, 1, 1) #These need to be [x, y, z]\n",
    "    grid_size = (int(np.ceil(a.shape[0] / block_size[0])), 1, 1)\n",
    "\n",
    "    #print(\"Block size is \" + str(block_size))\n",
    "    #print(\"Grid size is \" + str(grid_size))\n",
    "    \n",
    "    #Execute program on device\n",
    "    with Timer(\"Kernel execution\") as t:\n",
    "        kernel.prepared_async_call(grid_size,block_size,stream,\\\n",
    "                                   c_g.gpudata, a_g.gpudata, b_g.gpudata, \\\n",
    "                                   np.int32(a.shape[0]), np.int32(a.shape[1]))\n",
    "        context.synchronize()\n",
    "\n",
    "    #Copy data from device to host\n",
    "    with Timer(\"Allocate c\") as t:\n",
    "        c = np.empty((a.shape[0], 1), dtype=np.float32)\n",
    "    with Timer(\"Download\") as t:\n",
    "        c_g.get(c)\n",
    "        context.synchronize()\n",
    "    \n",
    "    #Return our computed matrix-vector product\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 101.673841 ms\n",
      "Data allocation: 0.821829 ms\n",
      "A upload: 6.522894 ms\n",
      "b upload: 0.824213 ms\n",
      "Kernel execution: 6.147623 ms\n",
      "Allocate c: 0.015497 ms\n",
      "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:43: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "Download: 0.314713 ms\n",
      "Run whole function: 22.640944 ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-706b2acf5927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run whole function\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpuMatrixVector_sync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'times' is not defined"
     ]
    }
   ],
   "source": [
    "#Size of our test\n",
    "test_size = (2048,2048)\n",
    "\n",
    "#Create test input / output data\n",
    "with Timer(\"Create test data\") as t:\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "with Timer(\"Run whole function\") as t:\n",
    "    c = gpuMatrixVector_sync(a, b)\n",
    "times[i] = t.msecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Before synchronisation\n",
    "```\n",
    "Create test data: 97.065926 ms\n",
    "Data allocation: 0.797749 ms\n",
    "A upload: 11.585474 ms\n",
    "b upload: 0.703812 ms\n",
    "Kernel execution: 5.970716 ms\n",
    "Allocate c: 0.014067 ms\n",
    "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:43: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
    "Download: 1.465082 ms\n",
    "Run whole function: 25.820971 ms\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  200   400   800  1600  3200  6400  8000 10000] [  200   400   800  1600  3200  6400  8000 10000]\n"
     ]
    }
   ],
   "source": [
    "nx = np.array([200, 400, 800, 1600, 3200, 6400, 8000, 10000])\n",
    "ny = nx\n",
    "\n",
    "print(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 1.783133 ms\n",
      "Data allocation: 1.528740 ms\n",
      "A upload: 1.235723 ms\n",
      "b upload: 0.769377 ms\n",
      "Kernel execution: 3.359795 ms\n",
      "Allocate c: 0.017643 ms\n",
      "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:39: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "Download: 2.933264 ms\n",
      "Run whole function: 19.097567 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 4.878044 ms\n",
      "Data allocation: 0.947237 ms\n",
      "A upload: 1.768589 ms\n",
      "b upload: 0.976801 ms\n",
      "Kernel execution: 0.940323 ms\n",
      "Allocate c: 0.015974 ms\n",
      "Download: 0.257969 ms\n",
      "Run whole function: 12.454271 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 16.592979 ms\n",
      "Data allocation: 1.572609 ms\n",
      "A upload: 1.882792 ms\n",
      "b upload: 1.022816 ms\n",
      "Kernel execution: 1.345873 ms\n",
      "Allocate c: 0.014305 ms\n",
      "Download: 0.175714 ms\n",
      "Run whole function: 12.216330 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 48.404455 ms\n",
      "Data allocation: 0.941515 ms\n",
      "A upload: 6.679535 ms\n",
      "b upload: 0.646353 ms\n",
      "Kernel execution: 3.712654 ms\n",
      "Allocate c: 0.011444 ms\n",
      "Download: 1.129627 ms\n",
      "Run whole function: 18.537998 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 169.073820 ms\n",
      "Data allocation: 1.115561 ms\n",
      "A upload: 26.330709 ms\n",
      "b upload: 0.886202 ms\n",
      "Kernel execution: 14.778852 ms\n",
      "Allocate c: 0.017166 ms\n",
      "Download: 0.391006 ms\n",
      "Run whole function: 49.223185 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 672.588587 ms\n",
      "Data allocation: 1.054049 ms\n",
      "A upload: 99.964142 ms\n",
      "b upload: 0.756025 ms\n",
      "Kernel execution: 77.190638 ms\n",
      "Allocate c: 0.015020 ms\n",
      "Download: 0.309229 ms\n",
      "Run whole function: 184.407949 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 834.132433 ms\n",
      "Data allocation: 1.963377 ms\n",
      "A upload: 155.528545 ms\n",
      "b upload: 0.817299 ms\n",
      "Kernel execution: 116.661072 ms\n",
      "Allocate c: 0.017166 ms\n",
      "Download: 0.195265 ms\n",
      "Run whole function: 280.435562 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 1301.924229 ms\n",
      "Data allocation: 1.302004 ms\n",
      "A upload: 242.333889 ms\n",
      "b upload: 0.570536 ms\n",
      "Kernel execution: 197.591782 ms\n",
      "Allocate c: 0.014305 ms\n",
      "Download: 0.635624 ms\n",
      "Run whole function: 448.789597 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    40000    160000    640000   2560000  10240000  40960000  64000000\n",
      " 100000000]\n",
      "[ 19  12  12  18  49 184 280 448]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fig = plt.figure()\\nplt.subplot(1,3,1)\\nplt.imshow(a)\\nplt.subplot(1,3,2)\\nplt.imshow(b)\\nplt.subplot(1,3,3)\\nplt.imshow(c)\\nfig.show()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = np.empty_like(nx)\n",
    "for i in range(len(nx)):\n",
    "    print(\"Nx = \" + str(nx[i]), flush=True)\n",
    "    #Size of our test\n",
    "    test_size = (nx[i], ny[i])\n",
    "\n",
    "    #Create test input / output data\n",
    "    with Timer(\"Create test data\") as t:\n",
    "        a = np.random.random(test_size).astype(np.float32)\n",
    "        b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "    with Timer(\"Run whole function\") as t:\n",
    "        c = gpuMatrixVector(a, b)\n",
    "    times[i] = t.msecs\n",
    "    \n",
    "print(nx*ny)\n",
    "print(times)\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\"fig = plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(a)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(b)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(c)\n",
    "fig.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f64d3ddd7b8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_title_pos\n",
      "findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(nx*ny, times, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad = 31.025146484375000000000000000000\n",
      "Per element error: 0.0031025146484375\n"
     ]
    }
   ],
   "source": [
    "#Compute reference using Numpy\n",
    "c_ref = np.dot(a, b)\n",
    "\n",
    "#Sum of absolute differences\n",
    "sad = np.sum(np.abs(c - c_ref))\n",
    "\n",
    "#Print result\n",
    "# print(\"C   = \", c)\n",
    "# print(\"Ref = \", c_ref)\n",
    "print(\"Sad = %.30f\" % sad)\n",
    "print(\"Per element error: \" + str(sad / test_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.6.6, pytest-3.8.2, py-1.6.0, pluggy-0.7.1 -- /home/jobic/anaconda3/envs/gpudev/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/jobic/test/cuda/milan2018/MilanoGPU2018/andre, inifile:\n",
      "collecting ... collected 1 item\n",
      "\n",
      "MatrixVectorTestingSingle.py::test_gpuMatrixVector <- <ipython-input-11-8148f6c0c3df> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data allocation: 0.986576 ms\n",
      "A upload: 0.781059 ms\n",
      "b upload: 0.773907 ms\n",
      "Kernel execution: 0.727415 ms\n",
      "Allocate c: 0.013828 ms\n",
      "Download: 1.101732 ms\n",
      "Data allocation: 0.579834 ms\n",
      "A upload: 0.574589 ms\n",
      "b upload: 0.629187 ms\n",
      "Kernel execution: 0.545502 ms\n",
      "Allocate c: 0.012398 ms\n",
      "Download: 0.813961 ms\n",
      "Data allocation: 0.558138 ms\n",
      "A upload: 0.458956 ms\n",
      "b upload: 0.442028 ms\n",
      "Kernel execution: 0.449419 ms\n",
      "Allocate c: 0.011921 ms\n",
      "Download: 0.241756 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED [100%]\n",
      "\n",
      "=============================== warnings summary ===============================\n",
      "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:39: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:39: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "/home/jobic/anaconda3/envs/gpudev/lib/python3.6/site-packages/ipykernel/__main__.py:39: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "===================== 1 passed, 3 warnings in 0.12 seconds =====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tests()\n",
    "\n",
    "def test_gpuMatrixVector():\n",
    "    #Let us test a matrix of size 1x1\n",
    "    a = np.ones((1, 1), dtype=np.float32)\n",
    "    b = 2*np.ones((1, 1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(2.0)\n",
    "    \n",
    "    #Test that the inner product works\n",
    "    a = np.ones((1, 2), dtype=np.float32)\n",
    "    b = 2*np.ones((2, 1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(4.0)\n",
    "    \n",
    "    #Test a general matrix\n",
    "    test_size = (4, 3)\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(a.dot(b), rel=1e-3)\n",
    "    \n",
    "run_pytest(filename='MatrixVectorTestingSingle.ipynb', pytest_options=['-vvv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpudev]",
   "language": "python",
   "name": "conda-env-gpudev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
