{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "    Jupyter notebook for accessing CUDA\n",
    "    Copyright (C) 2018 Andre.Brodtkorb@ifi.uio.no, changed in October by Andr√© Brodtkorb\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "import pycuda.driver as cuda_driver\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import IPythonMagic\n",
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from ipytest import run_pytest, clean_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python version 3.6.6 (default, Sep 12 2018, 18:26:19) \n",
      "[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n",
      "Registering context in user workspace\n",
      "Creating context\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (9, 1, 0)\n",
      "Driver version 10000\n",
      "Using 'Tesla K80' GPU\n",
      " => compute capability: (3, 7)\n",
      " => memory: 10764 / 11441 MB available\n",
      "Created context handle <33050096>\n",
      "Using CUDA cache dir /home/ubuntu/jupyter_notebooks/Andre Brodtkorb/MilanoGPU2018/notebooks/cuda_cache\n"
     ]
    }
   ],
   "source": [
    "%setup_logging\n",
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_kernel = \"\"\"\n",
    "__global__ void matrixVectorKernel(float* c, float* A, float* b, int a_rows, int a_cols) {\n",
    "    unsigned int j = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    \n",
    "    //Out of bounds check\n",
    "    if (j > a_rows) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    //Compute inner product of row of A with column of B\n",
    "    float sum = 0.0f;\n",
    "    for (int i=0; i<a_cols; ++i) {\n",
    "        unsigned int k = j*a_cols + i;\n",
    "        sum += A[k] * b[i];\n",
    "    }\n",
    "    \n",
    "    //Write to global memory\n",
    "    c[j] = sum;\n",
    "}\n",
    "\"\"\"\n",
    "module = cuda_compiler.SourceModule(cuda_kernel)\n",
    "kernel = module.get_function(\"matrixVectorKernel\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpuMatrixVector(a, b):\n",
    "    context.synchronize()\n",
    "        \n",
    "        \n",
    "    #Upload data to the device\n",
    "    #NOTE: We need to make sure that a=(a_rows, a_columns)\n",
    "    # and that b=(a_colmuns, 1) (column vector)\n",
    "    # and that c=(a_rows, 1)\n",
    "    with Timer(\"Data allocation\") as t:\n",
    "        a_g = GPUArray(a.shape, np.float32)\n",
    "        b_g = GPUArray(b.shape, np.float32)\n",
    "        c_g = GPUArray(a.shape[0], np.float32)\n",
    "        context.synchronize()\n",
    "        \n",
    "    with Timer(\"A upload\") as t:\n",
    "        a_g.set(a)\n",
    "        context.synchronize()\n",
    "        \n",
    "    with Timer(\"b upload\") as t:\n",
    "        b_g.set(b)\n",
    "        context.synchronize()\n",
    "    \n",
    "    #NOTE: We need to change this so that the grid*block is x = 1, y = number of rows in A\n",
    "    block_size = (128, 1, 1) #These need to be [x, y, z]\n",
    "    grid_size = (int(np.ceil(a.shape[0] / 128)), 1, 1)\n",
    "\n",
    "    #print(\"Block size is \" + str(block_size))\n",
    "    #print(\"Grid size is \" + str(grid_size))\n",
    "    \n",
    "    #Execute program on device\n",
    "    with Timer(\"Kernel execution\") as t:\n",
    "        kernel(c_g, a_g, b_g, np.int32(a.shape[0]), np.int32(a.shape[1]), block=block_size, grid=grid_size)\n",
    "        context.synchronize()\n",
    "\n",
    "    #Copy data from device to host\n",
    "    with Timer(\"Allocate c\") as t:\n",
    "        c = np.empty((a.shape[0], 1), dtype=np.float32)\n",
    "    with Timer(\"Download\") as t:\n",
    "        c_g.get(c)\n",
    "        context.synchronize()\n",
    "    \n",
    "    #Return our computed matrix-vector product\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  200   400   800  1600  3200  6400  8000 10000] [  200   400   800  1600  3200  6400  8000 10000]\n"
     ]
    }
   ],
   "source": [
    "nx = np.array([200, 400, 800, 1600, 3200, 6400, 8000, 10000])\n",
    "ny = nx\n",
    "\n",
    "print(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 9.123564 ms\n",
      "Data allocation: 0.969648 ms\n",
      "A upload: 0.256777 ms\n",
      "b upload: 0.466347 ms\n",
      "Kernel execution: 0.319958 ms\n",
      "Allocate c: 0.009775 ms\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:39: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "Download: 0.339270 ms\n",
      "Run whole function: 6.497622 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 3.687620 ms\n",
      "Data allocation: 0.694036 ms\n",
      "A upload: 0.339270 ms\n",
      "b upload: 0.405312 ms\n",
      "Kernel execution: 0.583649 ms\n",
      "Allocate c: 0.010729 ms\n",
      "Download: 0.219345 ms\n",
      "Run whole function: 6.124735 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 14.456749 ms\n",
      "Data allocation: 0.663757 ms\n",
      "A upload: 0.557423 ms\n",
      "b upload: 0.360250 ms\n",
      "Kernel execution: 0.742912 ms\n",
      "Allocate c: 0.010729 ms\n",
      "Download: 0.310183 ms\n",
      "Run whole function: 6.820679 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 44.214249 ms\n",
      "Data allocation: 0.710011 ms\n",
      "A upload: 1.603842 ms\n",
      "b upload: 0.160217 ms\n",
      "Kernel execution: 1.397371 ms\n",
      "Allocate c: 0.011206 ms\n",
      "Download: 0.445366 ms\n",
      "Run whole function: 9.840250 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 183.480501 ms\n",
      "Data allocation: 0.632048 ms\n",
      "A upload: 6.078720 ms\n",
      "b upload: 0.790119 ms\n",
      "Kernel execution: 3.593206 ms\n",
      "Allocate c: 0.010014 ms\n",
      "Download: 0.571012 ms\n",
      "Run whole function: 21.517038 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 734.246254 ms\n",
      "Data allocation: 0.775337 ms\n",
      "A upload: 22.109985 ms\n",
      "b upload: 0.222683 ms\n",
      "Kernel execution: 13.308764 ms\n",
      "Allocate c: 0.011206 ms\n",
      "Download: 0.255823 ms\n",
      "Run whole function: 63.791275 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 1127.634287 ms\n",
      "Data allocation: 1.287222 ms\n",
      "A upload: 34.493208 ms\n",
      "b upload: 0.201941 ms\n",
      "Kernel execution: 20.660877 ms\n",
      "Allocate c: 0.010252 ms\n",
      "Download: 0.152349 ms\n",
      "Run whole function: 94.066381 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 1749.052048 ms\n",
      "Data allocation: 1.168489 ms\n",
      "A upload: 53.019762 ms\n",
      "b upload: 0.704527 ms\n",
      "Kernel execution: 33.580065 ms\n",
      "Allocate c: 0.009775 ms\n",
      "Download: 0.149965 ms\n",
      "Run whole function: 143.804312 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    40000    160000    640000   2560000  10240000  40960000  64000000\n",
      " 100000000]\n",
      "[  6   6   6   9  21  63  94 143]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fig = plt.figure()\\nplt.subplot(1,3,1)\\nplt.imshow(a)\\nplt.subplot(1,3,2)\\nplt.imshow(b)\\nplt.subplot(1,3,3)\\nplt.imshow(c)\\nfig.show()'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = np.empty_like(nx)\n",
    "for i in range(len(nx)):\n",
    "    print(\"Nx = \" + str(nx[i]), flush=True)\n",
    "    #Size of our test\n",
    "    test_size = (nx[i], ny[i])\n",
    "\n",
    "    #Create test input / output data\n",
    "    with Timer(\"Create test data\") as t:\n",
    "        a = np.random.random(test_size).astype(np.float32)\n",
    "        b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "    with Timer(\"Run whole function\") as t:\n",
    "        c = gpuMatrixVector(a, b)\n",
    "    times[i] = t.msecs\n",
    "    \n",
    "print(nx*ny)\n",
    "print(times)\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\"fig = plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(a)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(b)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(c)\n",
    "fig.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4e40b4a5f8>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e40bcf780>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(nx*ny, times, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad = 0.000000000000000000000000000000\n",
      "Per element error: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Compute reference using Numpy\n",
    "c_ref = np.dot(a, b)\n",
    "\n",
    "#Sum of absolute differences\n",
    "sad = np.sum(np.abs(c - c_ref))\n",
    "\n",
    "#Print result\n",
    "# print(\"C   = \", c)\n",
    "# print(\"Ref = \", c_ref)\n",
    "print(\"Sad = %.30f\" % sad)\n",
    "print(\"Per element error: \" + str(sad / test_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.6.6, pytest-3.8.2, py-1.6.0, pluggy-0.7.1 -- /usr/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ubuntu/jupyter_notebooks/Andre Brodtkorb/MilanoGPU2018/notebooks, inifile:\n",
      "collecting ... collected 1 item\n",
      "\n",
      "MatrixVectorTesting.py::test_gpuMatrixVector <- <ipython-input-21-ac8844f07e97> PASSED [100%]\n",
      "\n",
      "=============================== warnings summary ===============================\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "===================== 1 passed, 3 warnings in 0.03 seconds =====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tests()\n",
    "\n",
    "def test_gpuMatrixVector():\n",
    "    #Let us test a matrix of size 1x1\n",
    "    a = np.ones((1, 1), dtype=np.float32)\n",
    "    b = 2*np.ones((1, 1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(2.0)\n",
    "    \n",
    "    #Test that the inner product works\n",
    "    a = np.ones((1, 2), dtype=np.float32)\n",
    "    b = 2*np.ones((2, 1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(4.0)\n",
    "    \n",
    "    #Test a general matrix\n",
    "    test_size = (4, 3)\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(a.dot(b), rel=1e-3)\n",
    "    \n",
    "run_pytest(filename='MatrixVectorTesting.ipynb', pytest_options=['-vvv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
